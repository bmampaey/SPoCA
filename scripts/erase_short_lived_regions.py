#!/usr/bin/env python3

import logging
import pandas
import numpy
from argparse import ArgumentParser
from pathlib import Path
from astropy.io import fits

def get_short_lived_region_tracked_colors(region_dataframe, min_lifespan):
	'''Return the set of tracked colors of the regions whose lifespan is shorter than the min'''
	
	# Using the value of the TRACKED_COLOR to identify regions through time
	# Compute the lifespan of the regions by taking their first date of observation and their last date of observation
	regions = region_dataframe.groupby('TRACKED_COLOR').aggregate(
		first_observation = pandas.NamedAgg(column='FIRST_DATE_OBS', aggfunc = 'min'),
		last_observation = pandas.NamedAgg(column='DATE_OBS', aggfunc = 'max'),
	)
	regions['lifespan'] = regions['last_observation'] - regions['first_observation']
	
	# Select the region for which the lifespan is shorter than the min_lifespan
	short_lived_regions = regions[regions['lifespan'] < min_lifespan]
	
	logging.debug('Found short lived regions :\n%s', short_lived_regions)
	
	return set(short_lived_regions.index)


def get_filepaths_with_region_colors(region_dataframe, tracked_colors, filepaths):
	'''Return the filepaths with the set of colors of the regions whose TRACKED_COLOR are in tracked_colors'''
	
	# We use groupby & apply to reduce the Dataframe to a Series where the index is the Filepath and the value is the set of COLOR for wich the corresponding TRACKED_COLOR is in tracked_colors
	
	def get_filtered_colors(group):
		filtered_regions = group[group['TRACKED_COLOR'].isin(tracked_colors)]
		return set(filtered_regions['COLOR'])
	
	return region_dataframe.groupby('Filepath').apply(get_filtered_colors).loc[filepaths].items()


def erase_regions_from_map(input_filepath, image_hdu_name_or_index, output_filepath, region_colors, background_color = 0):
	'''Write a new FITS map with the image but erase the regions in the image with a value in region colors'''
	
	with fits.open(input_filepath) as hdulist:
		image_hdu = hdulist[image_hdu_name_or_index]
		
		# If there are colors to erase, set the corresponding pixels of the image to the background_color
		# Else just copy the image
		if region_colors:
			logging.debug('Removing regions with colors %s from file %s', region_colors, input_filepath)
			image = image_hdu.data
			# numpy.isin does not accept a "set" as a parameter so convert region_colors to a list
			image[numpy.isin(image, list(region_colors))] = background_color
		
		# Write the cleaned image to the new map
		logging.info('Writing CH map %s', output_filepath)
		image_hdu.writeto(output_filepath, checksum = True)


# Start point of the script
if __name__ == '__main__':
	
	# Get the arguments
	parser = ArgumentParser(description='Erase regions in tracked SPoCA map FITS files that have a lifespan shorter than a specified minimum')
	parser.add_argument('--min-lifespan', '-m', required = True, type = pandas.Timedelta, help = 'The minimum lifespan')
	parser.add_argument('--region-csv', metavar = 'FILEPATH', required = True, help = 'The path to the CSV file containg the regions as generated by the script aggregate_tables_from_fits.py')
	parser.add_argument('--background-color', metavar = 'NUMBER', default = 0, help = 'The value to set the pixels of the regions that will be erased (default to 0)')
	parser.add_argument('--output', '-o', default = '.', type = Path, help = 'Path of the output directory')
	group = parser.add_mutually_exclusive_group()
	group.add_argument('--hdu-index', metavar = 'NUMBER', type = int, default = 0, dest = 'image_hdu_name_or_index', help = 'The index of the table HDU containing the image (default 0)')
	group.add_argument('--hdu-name', metavar = 'NAME', dest = 'image_hdu_name_or_index', help = 'The name of the table HDU containing the image')
	parser.add_argument('--verbose', '-v', choices = ['DEBUG', 'INFO', 'ERROR'], default = 'INFO', help = 'Set the logging level (default is INFO)')
	parser.add_argument('filepaths', nargs = '+', metavar = 'FILEPATH', help = 'The path to a SPoCA fits map (must be identical to the value in the Filepath column in the regions CSV file)')
	args = parser.parse_args()
	
	# Setup the logging
	logging.basicConfig(level = getattr(logging, args.verbose), format = '%(asctime)s %(levelname)-8s: %(message)s')
	
	# Create a dataframe from the region csv
	try:
		region_dataframe = pandas.read_csv(args.region_csv, index_col = ['Filepath', 'Row'], usecols = ['Filepath', 'Row', 'FIRST_DATE_OBS', 'DATE_OBS', 'COLOR', 'TRACKED_COLOR'], parse_dates = ['FIRST_DATE_OBS', 'DATE_OBS'])
	except Exception as why:
		logging.critical('Could not read CSV file %s: %s', args.region_csv, why)
		raise
	
	tracked_colors = get_short_lived_region_tracked_colors(region_dataframe, args.min_lifespan)
	
	for filepath, region_colors in get_filepaths_with_region_colors(region_dataframe, tracked_colors, args.filepaths):
		erase_regions_from_map(filepath, args.image_hdu_name_or_index, args.output / Path(filepath).name, region_colors, args.background_color)
